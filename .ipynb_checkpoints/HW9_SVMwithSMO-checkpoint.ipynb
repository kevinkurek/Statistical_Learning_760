{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine with SMO algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create linearly-separable data set with some noise.\n",
    "2. Implement SVM with the SMO algorithm.\n",
    "\n",
    "Advantages of using SMO is that it breaks up the problem into smaller sub-problems which have analytical solutions, and thus are much easier to solve and are much faster to solve. SMO was designed by John Platt at Microsoft in 1998."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "X = np.random.rand(100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88065696, 0.50709155],\n",
       "       [0.10872465, 0.89479678],\n",
       "       [0.09117134, 0.5539555 ],\n",
       "       [0.42354502, 0.21050826],\n",
       "       [0.55169419, 0.21224146]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset of random number generation\n",
    "X[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Linearly Separable Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Line for linear separability: y < 3X - 1\n",
    "\n",
    "negative_points = []\n",
    "positive_points = []\n",
    "\n",
    "for i in range(len(X)):\n",
    "    if (3*X[i,0] - 1) < X[i,1]:\n",
    "        plt.scatter(X[i,0], X[i,1], c='r')\n",
    "        negative_points.append([X[i,0],X[i,1]])\n",
    "    else:\n",
    "        plt.scatter(X[i,0], X[i,1], c='b')\n",
    "        positive_points.append([X[i,0],X[i,1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single df with positive/negative classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.108725</td>\n",
       "      <td>0.894797</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.091171</td>\n",
       "      <td>0.553956</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.271227</td>\n",
       "      <td>0.562987</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.169994</td>\n",
       "      <td>0.602018</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.272529</td>\n",
       "      <td>0.623325</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1  y\n",
       "0  0.108725  0.894797 -1\n",
       "1  0.091171  0.553956 -1\n",
       "2  0.271227  0.562987 -1\n",
       "3  0.169994  0.602018 -1\n",
       "4  0.272529  0.623325 -1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset of negative and positive points\n",
    "import pandas as pd\n",
    "negative_points = pd.DataFrame(negative_points)\n",
    "positive_points = pd.DataFrame(positive_points)\n",
    "\n",
    "negative_points['y'] = -1\n",
    "positive_points['y'] = 1\n",
    "\n",
    "df = pd.concat([negative_points,positive_points])\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM class with SMO algorithm with helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SVM():\n",
    "    \n",
    "    def __init__(self, max_iterations=10000, kernel_type='linear', C = 1.0, epsilon = 0.001):\n",
    "        \n",
    "        self.kernels = {\n",
    "            'linear': self.kernel_linear,\n",
    "        }\n",
    "        self.max_iter = max_iterations\n",
    "        self.kernel_type = kernel_type\n",
    "        self.C = C\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        n, d = X.shape[0], X.shape[1]\n",
    "        alpha = np.zeros((n))\n",
    "        kernel = self.kernels[self.kernel_type]\n",
    "        \n",
    "        count = 0\n",
    "        while True:\n",
    "            count += 1\n",
    "            previous_alpha = np.copy(alpha)\n",
    "            \n",
    "            for j in range(0,n):\n",
    "                i = self.get_random_integer(0, n-1, j)\n",
    "                x_i, x_j, y_i, y_j = X[i,:], X[j,:], y[i], y[j]\n",
    "                \n",
    "                k_ij = kernel(x_i, x_i) + kernel(x_j, x_j) - 2 * kernel(x_i, x_j)\n",
    "                \n",
    "                if k_ij == 0:\n",
    "                    continue\n",
    "                alpha_prime_j, alpha_prime_i = alpha[j], alpha[i]\n",
    "                (L,H) = self.compute_L_H(self.C, alpha_prime_j, alpha_prime_i, y_j, y_i)\n",
    "                \n",
    "                # Current model parameters\n",
    "                self.w = self.calc_w(alpha, y, X)\n",
    "                self.b = self.calc_b(X, y, self.w)\n",
    "                \n",
    "                # Compute E_i and E_j\n",
    "                E_i = self.E(x_i, y_i, self.w, self.b)\n",
    "                E_j = self.E(x_j, y_j, self.w, self.b)\n",
    "                \n",
    "                # New alphas\n",
    "                alpha[j] = alpha_prime_j = float(y_j * (E_i - E_j)) / k_ij\n",
    "                alpha[j] = max(alpha[j], L)\n",
    "                alpha[j] = min(alpha[j], H)\n",
    "                \n",
    "                alpha[i] = alpha_prime_i + y_i*y_j * (alpha_prime_j - alpha[j])\n",
    "                \n",
    "            # Converg\n",
    "            difference = np.linalg.norm(alpha - previous_alpha)\n",
    "            \n",
    "            if difference < self.epsilon:\n",
    "                break\n",
    "                \n",
    "            if count >= self.max_iter:\n",
    "                print(\"Number of iterations has exceeded the maximum possible iterations\")\n",
    "                \n",
    "                return\n",
    "            \n",
    "        # Final Parameters\n",
    "        self.b = self.calc_b(X,y, self.w)\n",
    "        if self.kernel_type == 'linear':\n",
    "            self.w = self.calc_w(alpha, y, X)\n",
    "        \n",
    "        # Grap support vectors\n",
    "        alpha_index = np.where(alpha > 0)[0]\n",
    "        support_vectors = X.iloc[alpha_index, :]\n",
    "        return support_vectors, count\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.h(X, self.w, self.b)\n",
    "    \n",
    "    def calc_b(self, X, y, w):\n",
    "        temp_b = y - np.dot(w.T, X.T)\n",
    "        return np.mean(temp_b)\n",
    "    \n",
    "    def calc_w(self, alpha, y, X):\n",
    "        return np.dot(alpha * y, X)\n",
    "    \n",
    "    # Predict\n",
    "    def h(self, X, w, b):\n",
    "        return np.sign(np.dot(w.T, X.T) + b).astype(int)\n",
    "    \n",
    "    # Error\n",
    "    def E(self, x_k, y_k, w, b):\n",
    "        return self.h(x_k, w, b) - y_k\n",
    "    \n",
    "    def compute_L_H(self, C, alpha_prime_j, alpha_prime_i, y_j, y_i):\n",
    "        if (y_i != y_j):\n",
    "            return (max(0, alpha_prime_j - alpha_prime_i), min(C, C - alpha_prime_i + alpha_prime_j))\n",
    "        else:\n",
    "            return (max(0, alpha_prime_i + alpha_prime_j - C), min(C, alpha_prime_i + alpha_prime_j))\n",
    "    \n",
    "    def get_random_integer(self, a, b, z):\n",
    "        i = z\n",
    "        count1 = 0\n",
    "        while i == z and count1<1000:\n",
    "            i = np.random.randint(a,b)\n",
    "            count1 += 1\n",
    "        return i\n",
    "\n",
    "    def kernel_linear(self, x1, x2):\n",
    "        return np.dot(x1, x2.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size = .3)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit & Predict on training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "SVM = SVC()\n",
    "SVM.fit(X_train,y_train)\n",
    "y_pred = SVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Classification Report and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "negative class (-1)       1.00      1.00      1.00        18\n",
      " positive class (1)       1.00      1.00      1.00        12\n",
      "\n",
      "        avg / total       1.00      1.00      1.00        30\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[18,  0],\n",
       "       [ 0, 12]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names = ['negative class (-1)','positive class (1)']))\n",
    "confusion_matrix(y_test, y_pred, labels=[-1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The algorithm predicted with 100% accuracy on the test set.\n",
    "This shouldn't come as a surprise since we generated the data as being linearly separable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
